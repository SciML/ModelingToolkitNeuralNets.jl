<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Symbolic UDE Creation · ModelingToolkitNeuralNets.jl</title><meta name="title" content="Symbolic UDE Creation · ModelingToolkitNeuralNets.jl"/><meta property="og:title" content="Symbolic UDE Creation · ModelingToolkitNeuralNets.jl"/><meta property="twitter:title" content="Symbolic UDE Creation · ModelingToolkitNeuralNets.jl"/><meta name="description" content="Documentation for ModelingToolkitNeuralNets.jl."/><meta property="og:description" content="Documentation for ModelingToolkitNeuralNets.jl."/><meta property="twitter:description" content="Documentation for ModelingToolkitNeuralNets.jl."/><meta property="og:url" content="https://docs.sciml.ai/ModelingToolkitNeuralNets.jl/stable/symbolic_ude_tutorial/"/><meta property="twitter:url" content="https://docs.sciml.ai/ModelingToolkitNeuralNets.jl/stable/symbolic_ude_tutorial/"/><link rel="canonical" href="https://docs.sciml.ai/ModelingToolkitNeuralNets.jl/stable/symbolic_ude_tutorial/"/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script><link href="../assets/favicon.ico" rel="icon" type="image/x-icon"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../"><img src="../assets/logo.png" alt="ModelingToolkitNeuralNets.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../">ModelingToolkitNeuralNets.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><span class="tocitem">Tutorials</span><ul><li><a class="tocitem" href="../nnblock/">NeuralNetworkBlock</a></li><li><a class="tocitem" href="../friction/">Friction Model</a></li><li class="is-active"><a class="tocitem" href>Symbolic UDE Creation</a></li></ul></li><li><a class="tocitem" href="../api/">API</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Tutorials</a></li><li class="is-active"><a href>Symbolic UDE Creation</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Symbolic UDE Creation</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/SciML/ModelingToolkitNeuralNets.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/SciML/ModelingToolkitNeuralNets.jl/blob/main/docs/src/symbolic_ude_tutorial.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Symbolic-UDE-Creation"><a class="docs-heading-anchor" href="#Symbolic-UDE-Creation">Symbolic UDE Creation</a><a id="Symbolic-UDE-Creation-1"></a><a class="docs-heading-anchor-permalink" href="#Symbolic-UDE-Creation" title="Permalink"></a></h1><p>This tutorial will demonstrate a simple interface for symbolic declaration neural networks that can be directly added to <a href="https://github.com/SciML/ModelingToolkit.jl">ModelingToolkit.jl</a>-declared ODE models to create UDEs. The primarily functionality we show is the <a href="../api/#ModelingToolkitNeuralNets.SymbolicNeuralNetwork"><code>SymbolicNeuralNetwork</code></a> function, however, we will show how it can be incorporated into a full workflow. For our example we will use a simple self-activation loop model, however, it can be easily generalised to more model types.</p><h3 id="Ground-truth-model-and-synthetic-data-generation"><a class="docs-heading-anchor" href="#Ground-truth-model-and-synthetic-data-generation">Ground truth model and synthetic data generation</a><a id="Ground-truth-model-and-synthetic-data-generation-1"></a><a class="docs-heading-anchor-permalink" href="#Ground-truth-model-and-synthetic-data-generation" title="Permalink"></a></h3><p>First we create the ground-truth model using ModelingToolkit. In it, <code>Y</code> activates <code>X</code> at the rate <code>v * (Y^n) / (K^n + Y^n)</code>. Later on, we will attempt to learn this rate using a neural network. Both variables decay at constant rates that scales with the parameter <code>d</code>.</p><pre><code class="language-julia hljs">using ModelingToolkit
using ModelingToolkit: t_nounits as t, D_nounits as D
@variables X(t) Y(t)
@parameters v=1.0 K=1.0 n=1.0 d=1.0 # Sets unused default values for all parameters (but vaguely useful as potential optimization initial conditions).
eqs = [D(X) ~ v * (Y^n) / (K^n + Y^n) - d*X
       D(Y) ~ X - d*Y]
@mtkcompile xy_model = System(eqs, t)</code></pre><p class="math-container">\[ \begin{align}
\frac{\mathrm{d} Y\left( t \right)}{\mathrm{d}t} &amp;= X\left( t \right) - d Y\left( t \right) \\
\frac{\mathrm{d} X\left( t \right)}{\mathrm{d}t} &amp;= \frac{\left( Y\left( t \right) \right)^{n} v}{\left( Y\left( t \right) \right)^{n} + K^{n}} - d X\left( t \right)
\end{align}
 \]</p><p>Next, we simulate our model for a true parameter set (which we wish to recover).</p><pre><code class="language-julia hljs">using OrdinaryDiffEqTsit5, Plots
u0 = [X =&gt; 2.0, Y =&gt; 0.1]
ps_true = [v =&gt; 1.1, K =&gt; 2.0, n =&gt; 3.0, d =&gt; 0.5]
sim_cond = [u0; ps_true]
tend = 45.0
oprob_true = ODEProblem(xy_model, sim_cond, (0.0, tend))
sol_true = solve(oprob_true, Tsit5())
plot(sol_true; lw = 6, idxs = [X, Y])</code></pre><img src="bd8550ee.svg" alt="Example block output"/><p>Finally, we generate noisy measured samples from both <code>X</code> and <code>Y</code> (to which we will fit the UDE).</p><pre><code class="language-julia hljs">sample_t = range(0.0, tend; length = 20)
sample_X = [(0.8 + 0.4rand()) * X_sample for X_sample in sol_true(sample_t; idxs = X)]
sample_Y = [(0.8 + 0.4rand()) * Y_sample for Y_sample in sol_true(sample_t; idxs = Y)]
plot!(sample_t, sample_X, seriestype = :scatter,
    label = &quot;X (data)&quot;, color = 1, ms = 6, alpha = 0.7)
plot!(sample_t, sample_Y, seriestype = :scatter,
    label = &quot;Y (data)&quot;, color = 2, ms = 6, alpha = 0.7)</code></pre><img src="2d09dd08.svg" alt="Example block output"/><h3 id="UDE-declaration-and-training"><a class="docs-heading-anchor" href="#UDE-declaration-and-training">UDE declaration and training</a><a id="UDE-declaration-and-training-1"></a><a class="docs-heading-anchor-permalink" href="#UDE-declaration-and-training" title="Permalink"></a></h3><p>First, we use <a href="https://github.com/LuxDL/Lux.jl">Lux.jl</a> to declare the neural network we wish to use for our UDE. For this case, we can use a fairly small network. We use <code>softplus</code> throughout the network we ensure that the fitted UDE function is positive (for our application this is the case, however, it might not always be true).</p><pre><code class="language-julia hljs">using Lux
nn_arch = Lux.Chain(
    Lux.Dense(1 =&gt; 3, Lux.softplus, use_bias = false),
    Lux.Dense(3 =&gt; 3, Lux.softplus, use_bias = false),
    Lux.Dense(3 =&gt; 1, Lux.softplus, use_bias = false)
)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Chain(
    layer_1 = Dense(1 =&gt; 3, softplus, use_bias=false),  <span class="sgr90"># 3 parameters</span>
    layer_2 = Dense(3 =&gt; 3, softplus, use_bias=false),  <span class="sgr90"># 9 parameters</span>
    layer_3 = Dense(3 =&gt; 1, softplus, use_bias=false),  <span class="sgr90"># 3 parameters</span>
) <span class="sgr90">        # Total: </span>15 parameters,
<span class="sgr90">          #        plus </span>0 states.</code></pre><p>Next, we can use <a href="https://github.com/SciML/ModelingToolkitNeuralNets.jl">ModelingToolkitNeuralNets.jl</a> to turn our neural network to a Symbolic neural network representation (which can later be inserted into an ModelingToolkit model).</p><pre><code class="language-julia hljs">using ModelingToolkitNeuralNets
sym_nn,
θ = SymbolicNeuralNetwork(; nn_p_name = :θ, chain = nn_arch, n_input = 1, n_output = 1)
sym_nn_func(x) = sym_nn(x, θ)[1]</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">sym_nn_func (generic function with 1 method)</code></pre><p>Now we can create our UDE. We replace the (from now on unknown) function <code>v * (Y^n) / (K^n + Y^n)</code> with our symbolic neural network (which we let be a function of the variable <code>Y</code> only).</p><pre><code class="language-julia hljs">eqs_ude = [D(X) ~ sym_nn_func(Y) - d*X
           D(Y) ~ X - d*Y]
@mtkcompile xy_model_ude = System(eqs_ude, t)</code></pre><p class="math-container">\[ \begin{align}
\frac{\mathrm{d} Y\left( t \right)}{\mathrm{d}t} &amp;= X\left( t \right) - d Y\left( t \right) \\
\frac{\mathrm{d} X\left( t \right)}{\mathrm{d}t} &amp;= \mathtt{NN}\_{1}\left( Y\left( t \right), \theta \right) - d X\left( t \right)
\end{align}
 \]</p><p>We can now fit our UDE model (including the neural network and the parameter d) to the data. First, we define a loss function which compares the UDE&#39;s simulation to the data.</p><pre><code class="language-julia hljs">function loss(ps, (oprob_base, set_ps, sample_t, sample_X, sample_Y))
    p = set_ps(oprob_base, ps)
    new_oprob = remake(oprob_base; p)
    new_osol = solve(new_oprob, Tsit5(); saveat = sample_t, verbose = false)
    SciMLBase.successful_retcode(new_osol) || return Inf # Simulation failed -&gt; Inf loss.
    x_error = sum((x_sim - x_data)^2 for (x_sim, x_data) in zip(new_osol[X], sample_X))
    y_error = sum((y_sim - y_data)^2 for (y_sim, y_data) in zip(new_osol[Y], sample_Y))
    return x_error + y_error
end</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">loss (generic function with 1 method)</code></pre><p>Next, we use <a href="https://github.com/SciML/Optimization.jl">Optimization.jl</a> to create an <code>OptimizationProblem</code>. This uses a similar syntax to normal parameter inference workflows, however, we need to add the entire neural network parameterisation to the optimization parameter vector.</p><pre><code class="language-julia hljs">using Optimization
using SymbolicIndexingInterface: setp_oop
oprob_base = ODEProblem(xy_model_ude, u0, (0.0, tend))
set_ps = setp_oop(oprob_base, [d; θ])
loss_params = (oprob_base, set_ps, sample_t, sample_X, sample_Y)
ps_init = oprob_base.ps[[d; θ]]
of = OptimizationFunction(loss, AutoForwardDiff())
opt_prob = OptimizationProblem(of, ps_init, loss_params)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi"><span class="sgr38_2" style="color:#56b6c2">OptimizationProblem</span>. In-place: <span class="sgr38_2" style="color:#56b6c2">true</span>
u0: 16-element Vector{Float64}:
  1.0
 -0.04929668828845024
 -0.3266667425632477
 -1.6716315746307373
 -0.5999714136123657
  0.7242816686630249
 -0.458548903465271
 -0.8280583620071411
 -0.38509929180145264
  0.32322537899017334
 -0.32623517513275146
 -0.7673453092575073
  0.7302734851837158
 -0.16844713687896729
  0.4040088653564453
  0.28568029403686523</code></pre><p>Finally, we can fit the UDE to our data. We will use the Adam optimizer.</p><pre><code class="language-julia hljs">import OptimizationOptimisers: Adam
@time opt_sol = solve(opt_prob, Adam(0.01); maxiters = 10000)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">retcode: Default
u: 16-element Vector{Float64}:
  0.47023326731944026
  0.710564052100639
 -0.3268722104005933
 -0.45891520632705324
 -1.217010379641178
 -0.03910431010187718
 -0.263078680137765
  2.9284612553796765
 -0.2122768497452721
  0.5623521751163092
  4.410120377546628
 -1.4342549804732498
  0.349641471427089
 -1.0106341714264575
  0.15071638316294436
  0.8168099557260349</code></pre><p>By plotting a simulation from our fitted UDE, we can confirm that it can reproduce the ground-truth model.</p><pre><code class="language-julia hljs">oprob_fitted = remake(oprob_base; p = set_ps(oprob_base, opt_sol.u))
sol_fitted = solve(oprob_fitted, Tsit5())
plot!(sol_true; lw = 4, la = 0.7, linestyle = :dash, idxs = [X, Y], color = [:blue :red],
    label = [&quot;X (UDE)&quot; &quot;Y (UDE)&quot;])</code></pre><img src="e049ea8f.svg" alt="Example block output"/><p>We can also inspect how the function described by the neural network looks like and how does it compare to the known correct function</p><pre><code class="language-julia hljs">true_func(y) = 1.1 * (y^3) / (2^3 + y^3)
fitted_func(y) = oprob_fitted.ps[sym_nn](y, oprob_fitted.ps[θ])[1]

# Plots the true and fitted functions (we mostly got the correct one, but less accurate in some regions).
plot(true_func, 0.0, 5.0; lw=8, label=&quot;True function&quot;, color=:lightblue)
plot!(fitted_func, 0.0, 5.0; lw=6, label=&quot;Fitted function&quot;, color=:blue, la=0.7, linestyle=:dash)</code></pre><img src="4ebaac73.svg" alt="Example block output"/></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../friction/">« Friction Model</a><a class="docs-footer-nextpage" href="../api/">API »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.16.1 on <span class="colophon-date" title="Thursday 8 January 2026 06:57">Thursday 8 January 2026</span>. Using Julia version 1.12.4.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
