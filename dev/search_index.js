var documenterSearchIndex = {"docs":
[{"location":"api/#API","page":"API","title":"API","text":"","category":"section"},{"location":"api/#ModelingToolkitNeuralNets.NeuralNetworkBlock","page":"API","title":"ModelingToolkitNeuralNets.NeuralNetworkBlock","text":"NeuralNetworkBlock(; n_input = 1, n_output = 1,\n    chain = multi_layer_feed_forward(n_input, n_output),\n    rng = Xoshiro(0),\n    init_params = Lux.initialparameters(rng, chain),\n    eltype = Float64,\n    name)\n\nCreate a component neural network as a System.\n\n\n\n\n\n","category":"function"},{"location":"api/#ModelingToolkitNeuralNets.SymbolicNeuralNetwork","page":"API","title":"ModelingToolkitNeuralNets.SymbolicNeuralNetwork","text":"SymbolicNeuralNetwork(; n_input = 1, n_output = 1,\n    chain = multi_layer_feed_forward(n_input, n_output),\n    rng = Xoshiro(0),\n    init_params = Lux.initialparameters(rng, chain),\n    nn_name =  :NN,\n    nn_p_name = :p,\n    eltype = Float64)\n\nCreate symbolic parameter for a neural network and one for its parameters. Example:\n\nchain = multi_layer_feed_forward(2, 2)\nNN, p = SymbolicNeuralNetwork(; chain, n_input=2, n_output=2, rng = StableRNG(42))\n\nThe NN and p are symbolic parameters that can be used later as part of a system. To change the name of the symbolic variables, use nn_name and nn_p_name. To get the predictions of the neural network, use\n\npred ~ NN(input, p)\n\nwhere pred and input are a symbolic vector variable with the lengths n_output and n_input.\n\nTo use this outside of an equation, you can get the default values for the symbols and make a similar call\n\ndefaults(sys)[sys.NN](input, nn_p)\n\nwhere sys is a system (e.g. ODESystem) that contains NN, input is a vector of n_input length and nn_p is a vector representing parameter values for the neural network.\n\nTo get the underlying Lux model you can use get_network(defaults(sys)[sys.NN]) or\n\n\n\n\n\n","category":"function"},{"location":"api/#ModelingToolkitNeuralNets.multi_layer_feed_forward","page":"API","title":"ModelingToolkitNeuralNets.multi_layer_feed_forward","text":"multi_layer_feed_forward(; n_input, n_output, width::Int = 4,\n    depth::Int = 1, activation = tanh, use_bias = true, initial_scaling_factor = 1e-8)\n\nCreate a Lux.jl Chain for use in NeuralNetworkBlocks. The weights of the last layer are multiplied by the initial_scaling_factor in order to make the initial contribution of the network small and thus help with achieving a stable starting position for the training.\n\n\n\n\n\n","category":"function"},{"location":"nnblock/#Component-based-Universal-Differential-Equations-with-ModelingToolkit","page":"NeuralNetworkBlock","title":"Component based Universal Differential Equations with ModelingToolkit","text":"","category":"section"},{"location":"nnblock/","page":"NeuralNetworkBlock","title":"NeuralNetworkBlock","text":"ModelingToolkitNeuralNets provides 2 main interfaces for representing neural networks symbolically:","category":"page"},{"location":"nnblock/","page":"NeuralNetworkBlock","title":"NeuralNetworkBlock","text":"The NeuralNetworkBlock, which represents the neural network as a block component\nThe SymbolicNeuralNetwork, which represents the neural network via callable parameters","category":"page"},{"location":"nnblock/","page":"NeuralNetworkBlock","title":"NeuralNetworkBlock","text":"This tutorial will introduce the NeuralNetworkBlock. This representation is useful in the context of hierarchical acausal component-based model.","category":"page"},{"location":"nnblock/","page":"NeuralNetworkBlock","title":"NeuralNetworkBlock","text":"For such models we have a component representation that is converted to a a differential-algebraic equation (DAE) system, where the algebraic equations are given by the constraints and equalities between different component variables. The process of going from the component representation to the full DAE system at the end is referred to as structural simplification. In order to formulate Universal Differential Equations (UDEs) in this context, we could operate either operate before the structural simplification step or after that, on the resulting DAE system. We call these the component UDE formulation and the system UDE formulation.","category":"page"},{"location":"nnblock/","page":"NeuralNetworkBlock","title":"NeuralNetworkBlock","text":"The advantage of the component UDE formulation is that it allows us to represent the model discovery process in the block component formulation, allowing us to potentially target deeply nested parts of a model for the model discovery process. As such, this allows us to maximally reuse the existing information and also to have a result  that can be expressed in the same manner as the original model.","category":"page"},{"location":"nnblock/","page":"NeuralNetworkBlock","title":"NeuralNetworkBlock","text":"In the following we will explore a simple example with a thermal model built with components from the ModelingToolkitStandardLibrary.","category":"page"},{"location":"nnblock/","page":"NeuralNetworkBlock","title":"NeuralNetworkBlock","text":"We will first start with a model that we generate synthetic data from and then we will build a simpler model that we will use for model discovery and try to recover the dynamics from the original model.","category":"page"},{"location":"nnblock/","page":"NeuralNetworkBlock","title":"NeuralNetworkBlock","text":"Our model represents a pot (HeatCapacitor) that is heated. In the complete model we consider that we have a plate that delays the heating of the pot. In the simple model we just consider that the heat source is directly connected to the pot.","category":"page"},{"location":"nnblock/","page":"NeuralNetworkBlock","title":"NeuralNetworkBlock","text":"Let's start with the definitions of the 2 models","category":"page"},{"location":"nnblock/","page":"NeuralNetworkBlock","title":"NeuralNetworkBlock","text":"using ModelingToolkitNeuralNets, Lux\nusing ModelingToolkitStandardLibrary.Thermal\nusing ModelingToolkitStandardLibrary.Blocks\nusing ModelingToolkit\nusing ModelingToolkit: t_nounits as t, D_nounits as D\nusing OrdinaryDiffEqTsit5\nusing Plots\nusing StableRNGs\nusing SciMLBase\n\ninput_f(t) = (1+sin(0.005 * t^2))/2\n\n@mtkmodel PotWithPlate begin\n    @parameters begin\n        C1 = 1\n        C2 = 15\n    end\n    @components begin\n        input = Blocks.TimeVaryingFunction(f = input_f)\n        source = PrescribedHeatFlow(T_ref = 373.15)\n        plate = HeatCapacitor(C = C1, T = 273.15)\n        pot = HeatCapacitor(C = C2, T = 273.15)\n        conduction = ThermalConductor(G = 1)\n        air = ThermalConductor(G = 0.1)\n        env = FixedTemperature(T = 293.15)\n        Tsensor = TemperatureSensor()\n    end\n    @equations begin\n        connect(input.output, :u, source.Q_flow)\n        connect(source.port, plate.port)\n        connect(plate.port, conduction.port_a)\n        connect(conduction.port_b, pot.port)\n        connect(pot.port, air.port_a)\n        connect(air.port_b, env.port)\n        connect(pot.port, Tsensor.port)\n    end\nend\n@mtkmodel SimplePot begin\n    @parameters begin\n        C2 = 15\n    end\n    @components begin\n        input = Blocks.TimeVaryingFunction(f = input_f)\n        source = PrescribedHeatFlow(T_ref = 373.15)\n        pot = HeatCapacitor(C = C2, T = 273.15)\n        air = ThermalConductor(G = 0.1)\n        env = FixedTemperature(T = 293.15)\n        Tsensor = TemperatureSensor()\n    end\n    @equations begin\n        connect(input.output, :u, source.Q_flow)\n        connect(source.port, pot.port)\n        connect(pot.port, Tsensor.port)\n        connect(pot.port, air.port_a)\n        connect(air.port_b, env.port)\n    end\nend\n@mtkcompile sys1 = PotWithPlate()\n@mtkcompile sys2 = SimplePot()\n\n## solve and plot the temperature of the pot in the 2 systems\n\nprob1 = ODEProblem(sys1, Pair[], (0, 100.0))\nsol1 = solve(prob1, Tsit5(), reltol = 1e-6)\nprob2 = ODEProblem(sys2, Pair[], (0, 100.0))\nsol2 = solve(prob2, Tsit5(), reltol = 1e-6)\nplot(sol1, idxs = sys1.pot.T, label = \"pot.T in original system\")\nplot!(sol2, idxs = sys1.pot.T, label = \"pot.T in simplified system\")","category":"page"},{"location":"nnblock/","page":"NeuralNetworkBlock","title":"NeuralNetworkBlock","text":"If we take a closer look at the 2 models, the original system has 2 unknowns,","category":"page"},{"location":"nnblock/","page":"NeuralNetworkBlock","title":"NeuralNetworkBlock","text":"unknowns(sys1)","category":"page"},{"location":"nnblock/","page":"NeuralNetworkBlock","title":"NeuralNetworkBlock","text":"while the simplified system only has 1 unknown","category":"page"},{"location":"nnblock/","page":"NeuralNetworkBlock","title":"NeuralNetworkBlock","text":"unknowns(sys2)","category":"page"},{"location":"nnblock/","page":"NeuralNetworkBlock","title":"NeuralNetworkBlock","text":"With the component UDE approach, we want to add a new component in the model that would be connected between the source and the pot such that we can use it to discover the missing physics. To this end, we will build a ThermalNN component that adds a new state in the system (x) that is prescribed by the output of the neural network, but it also incorporates physics knoweledge about the system by formulating the component as something that outputs a heat flow rate based on some scaled input temperatures.","category":"page"},{"location":"nnblock/","page":"NeuralNetworkBlock","title":"NeuralNetworkBlock","text":"The system in this example is quite simple, so we will use a very small neural network with 1 hidden layer of size 4. For more complex dynamics, a larger network would be required. The inputs to out neural network will use scaled temperature values, such that we don't input numbers that would be too large for the chosen activation function. The chosen activation function will always output positive numbers for positive inputs, so this also makes physical sense for out component.","category":"page"},{"location":"nnblock/","page":"NeuralNetworkBlock","title":"NeuralNetworkBlock","text":"@mtkmodel ThermalNN begin\n    begin\n        n_input = 2\n        n_output = 1\n        chain = multi_layer_feed_forward(;\n            n_input, n_output, depth = 1, width = 4, activation = Lux.swish)\n    end\n    @components begin\n        port_a = HeatPort()\n        port_b = HeatPort()\n        nn = NeuralNetworkBlock(; n_input, n_output, chain, rng = StableRNG(1337))\n    end\n    @parameters begin\n        T0 = 273.15\n        T_range = 10\n        C1 = 1\n    end\n    @variables begin\n        dT(t), [guess = 0.0]\n        Q_flow(t), [guess = 0.0]\n        x(t) = T0\n    end\n    @equations begin\n        dT ~ port_a.T - port_b.T\n        port_a.Q_flow ~ Q_flow\n        C1*D(x) ~ Q_flow - nn.outputs[1]\n        port_a.T ~ x\n        nn.outputs[1] + port_b.Q_flow ~ 0\n        nn.inputs[1] ~ (x - T0) / T_range\n        nn.inputs[2] ~ (port_b.T - T0) / T_range\n    end\nend\n\n@mtkmodel NeuralPot begin\n    @parameters begin\n        C2 = 15\n    end\n    @components begin\n        input = Blocks.TimeVaryingFunction(f = input_f)\n        source = PrescribedHeatFlow(T_ref = 373.15)\n        pot = HeatCapacitor(C = C2, T = 273.15)\n        air = ThermalConductor(G = 0.1)\n        env = FixedTemperature(T = 293.15)\n        Tsensor = TemperatureSensor()\n        thermal_nn = ThermalNN()\n    end\n    @equations begin\n        connect(input.output, :u, source.Q_flow)\n        connect(pot.port, Tsensor.port)\n        connect(pot.port, air.port_a)\n        connect(air.port_b, env.port)\n        connect(source.port, thermal_nn.port_a)\n        connect(thermal_nn.port_b, pot.port)\n    end\nend\n\n@named model = NeuralPot()\nsys3 = mtkcompile(model)\n\n# Let's check that we can successfully simulate the system in the\n# initial state\nprob3 = ODEProblem(sys3, Pair[], (0, 100.0))\nsol3 = solve(prob3, Tsit5(), abstol = 1e-6, reltol = 1e-6)\n@assert SciMLBase.successful_retcode(sol3)","category":"page"},{"location":"nnblock/","page":"NeuralNetworkBlock","title":"NeuralNetworkBlock","text":"Now that we have the system with the embedded neural network, we can start training the network. The training will be formulated as an optimization problem where we will minimize the mean absolute squared distance between the predictions of the new system and the data obtained from the original system. In order to gain some insight into the training process we will also add a callback that will plot various quantities in the system versus their equivalents in the original system. In a more realistic scenario we would not have access to the original system, but we could still monitor how well we fit the training data and the system predictions.","category":"page"},{"location":"nnblock/","page":"NeuralNetworkBlock","title":"NeuralNetworkBlock","text":"using SymbolicIndexingInterface\nusing Optimization\nusing OptimizationOptimJL\nusing LineSearches\nusing Statistics\nusing SciMLSensitivity\nimport Zygote\n\ntp = Symbolics.scalarize(sys3.thermal_nn.nn.p)\nx0 = prob3.ps[tp]\n\noop_update = setsym_oop(prob3, tp);\n\nplot_cb = (opt_state,\n    loss) -> begin\n    opt_state.iter % 1000 ≠ 0 && return false\n    @info \"step $(opt_state.iter), loss: $loss\"\n\n    (new_u0, new_p) = oop_update(prob3, opt_state.u)\n    new_prob = remake(prob3, u0 = new_u0, p = new_p)\n    sol = solve(new_prob, Tsit5(), abstol = 1e-8, reltol = 1e-8)\n\n    plt = plot(sol,\n        layout = (2, 3),\n        idxs = [\n            sys3.thermal_nn.nn.inputs[1], sys3.thermal_nn.x,\n            sys3.thermal_nn.nn.outputs[1], sys3.thermal_nn.port_b.T,\n            sys3.pot.T, sys3.pot.port.Q_flow],\n        size = (950, 800))\n    plot!(plt,\n        sol1,\n        idxs = [\n            (sys1.conduction.port_a.T-273.15)/10, sys1.conduction.port_a.T,\n            sys1.conduction.port_a.Q_flow, sys1.conduction.port_b.T,\n            sys1.pot.T, sys1.pot.port.Q_flow])\n    display(plt)\n    false\nend\n\nfunction cost(x, opt_ps)\n    prob, oop_update, data, ts, get_T = opt_ps\n\n    u0, p = oop_update(prob, x)\n    new_prob = remake(prob; u0, p)\n\n    new_sol = solve(new_prob, Tsit5(), saveat = ts, abstol = 1e-8,\n        reltol = 1e-8, verbose = false, sensealg = GaussAdjoint())\n\n    !SciMLBase.successful_retcode(new_sol) && return Inf\n\n    mean(abs2.(get_T(new_sol) .- data))\nend\n\nof = OptimizationFunction(cost, AutoForwardDiff())\n\ndata = sol1[sys1.pot.T]\nget_T = getsym(prob3, sys3.pot.T)\nopt_ps = (prob3, oop_update, data, sol1.t, get_T);\n\nop = OptimizationProblem(of, x0, opt_ps)\n\nres = solve(op, Adam(); maxiters = 10_000, callback = plot_cb)\nop2 = OptimizationProblem(of, res.u, opt_ps)\nres2 = solve(op2, LBFGS(linesearch = BackTracking()); maxiters = 2000, callback = plot_cb)\n\n(new_u0, new_p) = oop_update(prob3, res2.u)\nnew_prob1 = remake(prob3, u0 = new_u0, p = new_p)\nnew_sol1 = solve(new_prob1, Tsit5(), abstol = 1e-6, reltol = 1e-6)\n\nplt = plot(new_sol1,\n    layout = (2, 3),\n    idxs = [\n        sys3.thermal_nn.nn.inputs[1], sys3.thermal_nn.x,\n        sys3.thermal_nn.nn.outputs[1], sys3.thermal_nn.port_b.T,\n        sys3.pot.T, sys3.pot.port.Q_flow],\n    size = (950, 800))\nplot!(plt,\n    sol1,\n    idxs = [\n        (sys1.conduction.port_a.T-273.15)/10, sys1.conduction.port_a.T,\n        sys1.conduction.port_a.Q_flow, sys1.conduction.port_b.T,\n        sys1.pot.T, sys1.pot.port.Q_flow],\n    ls = :dash)","category":"page"},{"location":"nnblock/","page":"NeuralNetworkBlock","title":"NeuralNetworkBlock","text":"As we can see from the final plot, the neural network fits very well and not only the training data fits, but also the rest of the predictions of the system match the original system. Let us also compare against the predictions of the incomplete system:","category":"page"},{"location":"nnblock/","page":"NeuralNetworkBlock","title":"NeuralNetworkBlock","text":"plot(sol1, label = [\"original sys: pot T\" \"original sys: plate T\"], lw = 3)\nplot!(sol3; idxs = [sys3.pot.T], label = \"untrained UDE\", lw = 2.5)\nplot!(sol2; idxs = [sys2.pot.T], label = \"incomplete sys: pot T\", lw = 2.5)\nplot!(new_sol1; idxs = [sys3.pot.T, sys3.thermal_nn.x],\n    label = \"trained UDE\", ls = :dash, lw = 2.5)","category":"page"},{"location":"nnblock/","page":"NeuralNetworkBlock","title":"NeuralNetworkBlock","text":"Now that our neural network is trained, we can go a step further and use SymbolicRegression.jl to find a symbolic expression for the function represented by the neural network.","category":"page"},{"location":"nnblock/","page":"NeuralNetworkBlock","title":"NeuralNetworkBlock","text":"using SymbolicRegression\n\nlux_model = new_sol1.ps[sys3.thermal_nn.nn.lux_model]\nnn_p = new_sol1.ps[sys3.thermal_nn.nn.p]\nT = new_sol1.ps[sys3.thermal_nn.nn.T]\n\nsr_input = reduce(hcat, new_sol1[sys3.thermal_nn.nn.inputs])\nsr_output = LuxCore.stateless_apply(lux_model, sr_input, convert(T, nn_p))\n\nequation_search(sr_input, sr_output)","category":"page"},{"location":"nnblock/","page":"NeuralNetworkBlock","title":"NeuralNetworkBlock","text":"Looking at the results above, we see that we have a term linear in the difference between its inputs, x₁ - x₂, which were the scaled temperature values. This also makes sense physically, as the heat flow rate through the missing components in our system is proportional with the temperature difference between the ports. Having the symbolic expression for the UDE results thus helps us understand the missing physics better.","category":"page"},{"location":"friction/#Modeling-Non-Linear-Friction-Model-using-UDEs","page":"Friction Model","title":"Modeling Non Linear Friction Model using UDEs","text":"","category":"section"},{"location":"friction/","page":"Friction Model","title":"Friction Model","text":"Friction between moving bodies is not trivial to model. There have been idealised linear models which are not always useful in complicated systems. There have been many theories and non linear models which we can use, but they are not perfect. The aim of this tutorial to use Universal Differential Equations to showcase how we can embed a neural network to learn an unknown non linear friction model.","category":"page"},{"location":"friction/#Julia-Environment","page":"Friction Model","title":"Julia Environment","text":"","category":"section"},{"location":"friction/","page":"Friction Model","title":"Friction Model","text":"First, lets import the required packages.","category":"page"},{"location":"friction/","page":"Friction Model","title":"Friction Model","text":"using ModelingToolkitNeuralNets\nusing ModelingToolkit\nimport ModelingToolkit.t_nounits as t\nimport ModelingToolkit.D_nounits as Dt\nusing ModelingToolkitStandardLibrary.Blocks\nusing OrdinaryDiffEqVerner\nusing Optimization\nusing OptimizationOptimisers: Adam\nusing SciMLStructures\nusing SciMLStructures: Tunable\nusing SymbolicIndexingInterface\nusing Statistics\nusing StableRNGs\nusing Lux\nusing Plots\nusing Test #hide","category":"page"},{"location":"friction/#Problem-Setup","page":"Friction Model","title":"Problem Setup","text":"","category":"section"},{"location":"friction/","page":"Friction Model","title":"Friction Model","text":"Let's use the friction model presented in https://www.mathworks.com/help/simscape/ref/translationalfriction.html for generating data.","category":"page"},{"location":"friction/","page":"Friction Model","title":"Friction Model","text":"Fbrk = 100.0\nvbrk = 10.0\nFc = 80.0\nvst = vbrk / 10\nvcol = vbrk * sqrt(2)\nfunction friction(v)\n    sqrt(2 * MathConstants.e) * (Fbrk - Fc) * exp(-(v / vst)^2) * (v / vst) +\n    Fc * tanh(v / vcol)\nend","category":"page"},{"location":"friction/","page":"Friction Model","title":"Friction Model","text":"Next, we define the model - an object sliding in 1D plane with a constant force Fu acting on it and friction force opposing the motion.","category":"page"},{"location":"friction/","page":"Friction Model","title":"Friction Model","text":"function friction_true()\n    @variables y(t) = 0.0\n    @constants Fu = 120.0\n    eqs = [\n        Dt(y) ~ Fu - friction(y)\n    ]\n    return System(eqs, t, name = :friction_true)\nend","category":"page"},{"location":"friction/","page":"Friction Model","title":"Friction Model","text":"Now that we have defined the model, we will simulate it from 0 to 0.1 seconds.","category":"page"},{"location":"friction/","page":"Friction Model","title":"Friction Model","text":"model_true = mtkcompile(friction_true())\nprob_true = ODEProblem(model_true, [], (0, 0.1))\nsol_ref = solve(prob_true, Vern7(); saveat = 0.001)","category":"page"},{"location":"friction/","page":"Friction Model","title":"Friction Model","text":"Let's plot it.","category":"page"},{"location":"friction/","page":"Friction Model","title":"Friction Model","text":"scatter(sol_ref, label = \"velocity\")","category":"page"},{"location":"friction/","page":"Friction Model","title":"Friction Model","text":"That was the velocity. Let's also plot the friction force acting on the object throughout the simulation.","category":"page"},{"location":"friction/","page":"Friction Model","title":"Friction Model","text":"scatter(sol_ref.t, friction.(first.(sol_ref.u)), label = \"friction force\")","category":"page"},{"location":"friction/#Model-Setup","page":"Friction Model","title":"Model Setup","text":"","category":"section"},{"location":"friction/","page":"Friction Model","title":"Friction Model","text":"Now, we will try to learn the same friction model using a neural network. We will use NeuralNetworkBlock to define neural network as a component. The input of the neural network is the velocity and the output is the friction force. We connect the neural network with the model using RealInputArray and RealOutputArray blocks.","category":"page"},{"location":"friction/","page":"Friction Model","title":"Friction Model","text":"function friction_ude(Fu)\n    @variables y(t) = 0.0\n    @constants Fu = Fu\n\n    chain = Lux.Chain(\n        Lux.Dense(1 => 10, Lux.mish, use_bias = false),\n        Lux.Dense(10 => 10, Lux.mish, use_bias = false),\n        Lux.Dense(10 => 1, use_bias = false)\n    )\n    @named nn = NeuralNetworkBlock(1, 1; chain = chain, rng = StableRNG(1111))\n\n    eqs = [Dt(y) ~ Fu - nn.outputs[1]\n           y ~ nn.inputs[1]]\n    return System(eqs, t, name = :friction, systems = [nn])\nend\n\nFu = 120.0\n\nude_sys = friction_ude(Fu)\nsys = mtkcompile(ude_sys)","category":"page"},{"location":"friction/#Optimization-Setup","page":"Friction Model","title":"Optimization Setup","text":"","category":"section"},{"location":"friction/","page":"Friction Model","title":"Friction Model","text":"We now setup the loss function and the optimization loop.","category":"page"},{"location":"friction/","page":"Friction Model","title":"Friction Model","text":"function loss(x, (prob, sol_ref, get_vars, get_refs, set_x))\n    new_p = set_x(prob, x)\n    new_prob = remake(prob, p = new_p, u0 = eltype(x).(prob.u0))\n    ts = sol_ref.t\n    new_sol = solve(new_prob, Vern7(), saveat = ts, abstol = 1e-8, reltol = 1e-8)\n\n    if SciMLBase.successful_retcode(new_sol)\n        mean(abs2.(reduce(hcat, get_vars(new_sol)) .- reduce(hcat, get_refs(sol_ref))))\n    else\n        Inf\n    end\nend\n\nof = OptimizationFunction(loss, AutoForwardDiff())\n\nprob = ODEProblem(sys, [], (0, 0.1))\nget_vars = getu(sys, [sys.y])\nget_refs = getu(model_true, [model_true.y])\nset_x = setp_oop(sys, sys.nn.p)\nx0 = default_values(sys)[sys.nn.p]\n\ncb = (opt_state, loss) -> begin\n    @info \"step $(opt_state.iter), loss: $loss\"\n    return false\nend\n\nop = OptimizationProblem(of, x0, (prob, sol_ref, get_vars, get_refs, set_x))\nres = solve(op, Adam(5e-3); maxiters = 10000, callback = cb)","category":"page"},{"location":"friction/#Visualization-of-results","page":"Friction Model","title":"Visualization of results","text":"","category":"section"},{"location":"friction/","page":"Friction Model","title":"Friction Model","text":"We now have a trained neural network! We can check whether running the simulation of the model embedded with the neural network matches the data or not.","category":"page"},{"location":"friction/","page":"Friction Model","title":"Friction Model","text":"res_p = set_x(prob, res.u)\nres_prob = remake(prob, p = res_p)\nres_sol = solve(res_prob, Vern7(), saveat = sol_ref.t)\n@test first.(sol_ref.u)≈first.(res_sol.u) rtol=1e-3 #hide\n@test friction.(first.(sol_ref.u))≈(getindex.(res_sol[sys.nn.outputs], 1)) rtol=1e-1 #hide\nnothing #hide","category":"page"},{"location":"friction/","page":"Friction Model","title":"Friction Model","text":"Also, it would be interesting to check the simulation before the training to get an idea of the starting point of the network.","category":"page"},{"location":"friction/","page":"Friction Model","title":"Friction Model","text":"initial_sol = solve(prob, Vern7(), saveat = sol_ref.t)","category":"page"},{"location":"friction/","page":"Friction Model","title":"Friction Model","text":"Now we plot it.","category":"page"},{"location":"friction/","page":"Friction Model","title":"Friction Model","text":"scatter(sol_ref, idxs = [model_true.y], label = \"ground truth velocity\")\nplot!(res_sol, idxs = [sys.y], label = \"velocity after training\")\nplot!(initial_sol, idxs = [sys.y], label = \"velocity before training\")","category":"page"},{"location":"friction/","page":"Friction Model","title":"Friction Model","text":"It matches the data well! Let's also check the predictions for the friction force and whether the network learnt the friction model or not.","category":"page"},{"location":"friction/","page":"Friction Model","title":"Friction Model","text":"scatter(sol_ref.t, friction.(first.(sol_ref.u)), label = \"ground truth friction\")\nplot!(res_sol.t, getindex.(res_sol[sys.nn.outputs], 1),\n    label = \"friction from neural network\")","category":"page"},{"location":"friction/","page":"Friction Model","title":"Friction Model","text":"It learns the friction model well!","category":"page"},{"location":"#ModelingToolkitNeuralNets.jl","page":"Home","title":"ModelingToolkitNeuralNets.jl","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"ModelingToolkitNeuralNets is a package that allows one to embed neural networks inside ModelingToolkit systems in order to formulate Universal Differential Equations. The neural network is symbolically represented either as a block component or a callable parameter, so it can be added to any part of the equations in an System which gives a lot of flexibility for model discovery, such that we make changes only to the relevant parts of the model in order to discover missing physics.","category":"page"},{"location":"#Installation","page":"Home","title":"Installation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"To install ModelingToolkitNeuralNets, use the Julia package manager:","category":"page"},{"location":"","page":"Home","title":"Home","text":"using Pkg\nPkg.add(\"ModelingToolkitNeuralNets\")","category":"page"},{"location":"","page":"Home","title":"Home","text":"or","category":"page"},{"location":"","page":"Home","title":"Home","text":"julia> ]add ModelingToolkitNeuralNets","category":"page"},{"location":"#Contributing","page":"Home","title":"Contributing","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Please refer to the SciML ColPrac: Contributor's Guide on Collaborative Practices for Community Packages for guidance on PRs, issues, and other matters relating to contributing to SciML.\nSee the SciML Style Guide for common coding practices and other style decisions.\nThere are a few community forums:\nThe #diffeq-bridged and #sciml-bridged channels in the Julia Slack\nThe #diffeq-bridged and #sciml-bridged channels in the Julia Zulip\nOn the Julia Discourse forums\nSee also SciML Community page","category":"page"},{"location":"#Reproducibility","page":"Home","title":"Reproducibility","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"<details><summary>The documentation of this SciML package was built using these direct dependencies,</summary>","category":"page"},{"location":"","page":"Home","title":"Home","text":"using Pkg # hide\nPkg.status() # hide","category":"page"},{"location":"","page":"Home","title":"Home","text":"</details>","category":"page"},{"location":"","page":"Home","title":"Home","text":"<details><summary>and using this machine and Julia version.</summary>","category":"page"},{"location":"","page":"Home","title":"Home","text":"using InteractiveUtils # hide\nversioninfo() # hide","category":"page"},{"location":"","page":"Home","title":"Home","text":"</details>","category":"page"},{"location":"","page":"Home","title":"Home","text":"<details><summary>A more complete overview of all dependencies and their versions is also provided.</summary>","category":"page"},{"location":"","page":"Home","title":"Home","text":"using Pkg # hide\nPkg.status(; mode = PKGMODE_MANIFEST) # hide","category":"page"},{"location":"","page":"Home","title":"Home","text":"</details>","category":"page"},{"location":"","page":"Home","title":"Home","text":"using TOML\nusing Markdown\nversion = TOML.parse(read(\"../../Project.toml\", String))[\"version\"]\nname = TOML.parse(read(\"../../Project.toml\", String))[\"name\"]\nlink_manifest = \"https://github.com/SciML/\" * name * \".jl/tree/gh-pages/v\" * version *\n                \"/assets/Manifest.toml\"\nlink_project = \"https://github.com/SciML/\" * name * \".jl/tree/gh-pages/v\" * version *\n               \"/assets/Project.toml\"\nMarkdown.parse(\"\"\"You can also download the\n[manifest]($link_manifest)\nfile and the\n[project]($link_project)\nfile.\n\"\"\")","category":"page"}]
}
